{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T10:24:11.110625200Z",
     "start_time": "2024-01-18T10:24:11.053049800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from random import seed\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import hypergeom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6614d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c88db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_directory_path = 'FUMA_dowloads_all_tissue/SNPs'\n",
    "eqtl_directory_path = 'FUMA_dowloads_all_tissue/eQTL'\n",
    "\n",
    "# Initialize list to store merged dataframes\n",
    "merged_dfs = []\n",
    "\n",
    "# Iterate through SNP and eQTL directories simultaneously\n",
    "for snp_file, eqtl_file in zip(os.listdir(snp_directory_path), os.listdir(eqtl_directory_path)):\n",
    "    if snp_file.endswith('.txt') and eqtl_file.endswith('.txt'):\n",
    "        # Extract disorder name from the filename\n",
    "        disorder_name = snp_file.split('_')[1].split('.')[0]\n",
    "\n",
    "        # Read SNP and eQTL files\n",
    "        snp_df = pd.read_csv(os.path.join(snp_directory_path, snp_file), sep='\\t')\n",
    "        eqtl_df = pd.read_csv(os.path.join(eqtl_directory_path, eqtl_file), sep='\\t', low_memory=False)\n",
    "\n",
    "        # Choose columns of interest in each dataframe\n",
    "        snp_df = snp_df[['uniqID', 'rsID', 'gwasP']].dropna().drop_duplicates()\n",
    "        eqtl_df = eqtl_df[['uniqID', 'symbol', 'tissue']].dropna().drop_duplicates()\n",
    "\n",
    "        # Merge SNP and eQTL dataframes on 'uniqID'\n",
    "        merged_df = pd.merge(snp_df, eqtl_df, on='uniqID', how='inner')\n",
    "\n",
    "        # Add disorder column\n",
    "        merged_df['disorder'] = disorder_name\n",
    "\n",
    "        # Append the merged dataframe to the list\n",
    "        merged_dfs.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1efab7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqID</th>\n",
       "      <th>rsID</th>\n",
       "      <th>gwasP</th>\n",
       "      <th>symbol</th>\n",
       "      <th>tissue</th>\n",
       "      <th>disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:19986252:C:G</td>\n",
       "      <td>rs4912014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>NBL1</td>\n",
       "      <td>Lepik_2017_ge_blood</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:19986252:C:G</td>\n",
       "      <td>rs4912014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>HTR6</td>\n",
       "      <td>Lepik_2017_ge_blood</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:19986252:C:G</td>\n",
       "      <td>rs4912014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>HTR6</td>\n",
       "      <td>TwinsUK_ge_blood</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:19986252:C:G</td>\n",
       "      <td>rs4912014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>NBL1</td>\n",
       "      <td>PsychENCODE_eQTLs</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:19986252:C:G</td>\n",
       "      <td>rs4912014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>HTR6</td>\n",
       "      <td>PsychENCODE_eQTLs</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214918</th>\n",
       "      <td>22:51109735:A:G</td>\n",
       "      <td>rs713692</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>Pancreas</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214919</th>\n",
       "      <td>22:51109735:A:G</td>\n",
       "      <td>rs713692</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>Cells_Cultured_fibroblasts</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214920</th>\n",
       "      <td>22:51109735:A:G</td>\n",
       "      <td>rs713692</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>Skin_Sun_Exposed_Lower_leg</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214921</th>\n",
       "      <td>22:51109735:A:G</td>\n",
       "      <td>rs713692</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>Thyroid</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214922</th>\n",
       "      <td>22:51109735:A:G</td>\n",
       "      <td>rs713692</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ARSA</td>\n",
       "      <td>Cells_Transformed_fibroblasts</td>\n",
       "      <td>BPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1214923 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uniqID       rsID     gwasP symbol  \\\n",
       "0         1:19986252:C:G  rs4912014  0.000028   NBL1   \n",
       "1         1:19986252:C:G  rs4912014  0.000028   HTR6   \n",
       "2         1:19986252:C:G  rs4912014  0.000028   HTR6   \n",
       "3         1:19986252:C:G  rs4912014  0.000028   NBL1   \n",
       "4         1:19986252:C:G  rs4912014  0.000028   HTR6   \n",
       "...                  ...        ...       ...    ...   \n",
       "1214918  22:51109735:A:G   rs713692  0.000005   ARSA   \n",
       "1214919  22:51109735:A:G   rs713692  0.000005   ARSA   \n",
       "1214920  22:51109735:A:G   rs713692  0.000005   ARSA   \n",
       "1214921  22:51109735:A:G   rs713692  0.000005   ARSA   \n",
       "1214922  22:51109735:A:G   rs713692  0.000005   ARSA   \n",
       "\n",
       "                                tissue disorder  \n",
       "0                  Lepik_2017_ge_blood      BPD  \n",
       "1                  Lepik_2017_ge_blood      BPD  \n",
       "2                     TwinsUK_ge_blood      BPD  \n",
       "3                    PsychENCODE_eQTLs      BPD  \n",
       "4                    PsychENCODE_eQTLs      BPD  \n",
       "...                                ...      ...  \n",
       "1214918                       Pancreas      BPD  \n",
       "1214919     Cells_Cultured_fibroblasts      BPD  \n",
       "1214920     Skin_Sun_Exposed_Lower_leg      BPD  \n",
       "1214921                        Thyroid      BPD  \n",
       "1214922  Cells_Transformed_fibroblasts      BPD  \n",
       "\n",
       "[1214923 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dfs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265efdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_matrix(df_list, column1,column2):\n",
    "    concatenated= pd.concat(df_list)\n",
    "    df = concatenated[[column1, column2]]\n",
    "    \n",
    "    return df.pivot_table(index=column1, columns=column2, aggfunc=lambda x: 1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ee07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snps_binary = make_binary_matrix(merged_dfs, 'rsID', 'disorder')\n",
    "all_genes_binary = make_binary_matrix(merged_dfs,'symbol', 'disorder')\n",
    "\"\"\" psych_snps_binary = make_binary_matrix(psych_snp_dfs,'rsID', 'disorder')\n",
    "genes_psych_binary = make_binary_matrix(psych_genes_dfs,'symbol', 'disorder') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_snps_binary.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_genes_binary.sum(axis=0))\n",
    "#all_genes_binary.to_csv('all_genes_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_row(binary_df):\n",
    "    row_sums = binary_df.sum(axis=1)\n",
    "\n",
    "    # Find the maximum sum\n",
    "    max_row_sum = row_sums.max()\n",
    "    \n",
    "    print(\"Maximum number of 1's in the row:\", max_row_sum)\n",
    "    return max_row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_combo_snps = find_max_row(all_snps_binary)\n",
    "max_combo_genes = find_max_row(all_genes_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_combos(binary_df, max_combo):\n",
    "\n",
    "    num_iterations = 10\n",
    "\n",
    "    # Get all possible combinations of disorders\n",
    "    all_combinations = []\n",
    "    for r in range(2,max_combo):\n",
    "        all_combinations.extend(list(combinations(binary_df.columns, r)))\n",
    "\n",
    "    # Create an empty DataFrame with rows as each combination and columns for storing counts in each iteration\n",
    "    counts_df = pd.DataFrame(index=all_combinations, columns=range(1,num_iterations+1))\n",
    "\n",
    "    # Perform the iterations\n",
    "    for i in range(1,num_iterations+1):\n",
    "        # Permute the columns independently\n",
    "        permuted_df = binary_df.apply(np.random.permutation, axis=0)\n",
    "\n",
    "        iteration_counts = []\n",
    "\n",
    "        # Count occurrences for each combination in this iteration\n",
    "        for combo in all_combinations:\n",
    "            # Check if all disorders in the combination are present in each row\n",
    "            count = (permuted_df[list(combo)] == 1).all(axis=1).sum()\n",
    "            iteration_counts.append(count)\n",
    "\n",
    "        # Store the counts for this iteration in the dataFrame\n",
    "        counts_df[i] = iteration_counts\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143852d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_combos_real_data(binary_df, max_combo):\n",
    "#Count all occurrences for each combination and store in a new dataframe\n",
    "\n",
    "    # Get all possible combinations of disorders \n",
    "    all_combinations = []\n",
    "    for r in range(2,max_combo):\n",
    "        all_combinations.extend(list(combinations(binary_df.columns, r)))\n",
    "        \n",
    "    #Create empty dataframe to store the count\n",
    "    count_df = pd.DataFrame(index=all_combinations, columns=['Count'])\n",
    "\n",
    "    iteration_counts = []\n",
    "\n",
    "    # Count occurrences for each combination in this iteration \n",
    "    for combo in all_combinations:\n",
    "        # Check if all disorders in the combination are present in each row\n",
    "        count = (binary_df[list(combo)] == 1).all(axis=1).sum()\n",
    "        iteration_counts.append(count)\n",
    "\n",
    "    # Store the counts for this iteration in the counts_df DataFrame\n",
    "    count_df['Count'] = iteration_counts\n",
    "    \n",
    "    return count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_snps_randomized = count_combos(all_snps_binary, 6)\n",
    "all_genes_combo_count = count_combos_real_data(all_genes_binary, 6)\n",
    "all_genes_randomized = count_combos(all_genes_binary, 6)\n",
    "all_snps_combo_count = count_combos_real_data(all_snps_binary, 6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate z-scores and sort the result\n",
    "\n",
    "def calculate_z_score(df, df_rand, threshold, count):\n",
    "    \n",
    "    #calculate mean and standard deviation\n",
    "    means = round(df_rand.mean(axis=1),2)\n",
    "    std = round(df_rand.std(axis=1),2)\n",
    "\n",
    "    df_rand['mean'] = means\n",
    "    df_rand['std'] = std\n",
    "    df_rand['actual'] = df['Count']\n",
    "    \n",
    "    new_df = df_rand[['actual', 'mean', 'std']]\n",
    "    \n",
    "    #Make copies to avoid warnings\n",
    "    new_df_copy = new_df.copy()\n",
    "    \n",
    "    \n",
    "    # Calculate Z-scores \n",
    "    new_df_copy['z-score'] = round((new_df_copy['actual'] - new_df_copy['mean']) / new_df_copy['std'],2)\n",
    "    \n",
    "    \n",
    "    sorted_df = new_df_copy.sort_values(by='z-score', ascending=False)\n",
    "    \n",
    "    # Replace infinite values in the \"z-score\" column with NaN\n",
    "    sorted_df['z-score'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Drop rows with NaN values in the \"z-score\" column\n",
    "    sorted_df.dropna(subset=['z-score'], how='any', inplace=True)\n",
    "\n",
    "    return sorted_df[(sorted_df['z-score'] >= threshold) & (sorted_df['actual'] >= count)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e52b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_snps2 = calculate_z_score(all_snps_combo_count, all_snps_randomized,2,5)\n",
    "z_all_genes2 = calculate_z_score(all_genes_combo_count, all_genes_randomized,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_genes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226879db",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {'No. of combinations with z-value >= 2':[len(z_all_snps2),len(z_all_genes2)]}\n",
    "z_df = pd.DataFrame(data=z, index=['SNPs', 'Genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = hierarchy.linkage(all_snps_binary.T, method='average', metric='hamming')\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram = hierarchy.dendrogram(link, labels=all_snps_binary.columns)\n",
    "plt.xlabel('Disorders')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Hierarchical Clustering Dendrogram SNPs')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 500 SNPs/genes ranked by significance\n",
    "top_snp_list = []\n",
    "for df in merged_dfs:\n",
    "    sorted = df.sort_values(by=['gwasP'])\n",
    "    top_snps = sorted.iloc[:500]\n",
    "    top_snps.reset_index(drop=True,inplace=True)\n",
    "    top_snp_list.append(top_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23871cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  randomly select a given number of SNPs\n",
    "\n",
    "all_linkage = []\n",
    "\n",
    "# Perform hierarchical clustering 10 times and store the linkage matrices\n",
    "for _ in range(5):\n",
    "    sampled_dfs = []\n",
    "    for df in top_snp_list:\n",
    "        sampled = df.sample(100, axis=0, replace=True)\n",
    "        sampled.reset_index(inplace=True, drop=True)\n",
    "        sampled_dfs.append(sampled)\n",
    "\n",
    "    sampled_binary = make_binary_matrix(sampled_dfs, 'rsID', 'disorder')\n",
    "    \n",
    "\n",
    "    # Hierarchical clustering\n",
    "    linkage_matrix = hierarchy.linkage(sampled_binary.T, method='average')\n",
    "    all_linkage.append(linkage_matrix)\n",
    "\n",
    "# Plot the dendrogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    dendrogram = hierarchy.dendrogram(linkage_matrix, labels=sampled_binary.columns)\n",
    "    plt.xlabel('Disorders')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title('Hierarchical Clustering Dendrogram sampled from top 500 SNPs/genes')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()  \n",
    "\n",
    "\"\"\" # Compute the mean linkage matrix\n",
    "mean_linkage = np.mean(all_linkage, axis=0)\n",
    "print(mean_linkage)\n",
    "# Plot the dendrogram for the mean linkage matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram = hierarchy.dendrogram(mean_linkage)\n",
    "plt.xlabel('Disorders')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Consensus Hierarchical Clustering Dendrogram')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c330e40c7802c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T12:56:19.970956Z",
     "start_time": "2024-01-17T12:56:19.923473300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to find the overlaps in SNPs and genes\n",
    "\n",
    "def find_overlaps(binary_matrix, disorders_of_interest):\n",
    "    overlaps = []\n",
    "    overlapping_genes = set()\n",
    "\n",
    "    for index, row in binary_matrix.iterrows():\n",
    "        ones = {col for col, val in row.items() if val == 1 and col in disorders_of_interest}\n",
    "\n",
    "        if ones and ones == set(disorders_of_interest):\n",
    "            overlaps.append((index, ones))\n",
    "            overlapping_genes.add(index)\n",
    "\n",
    "    return overlaps, list(overlapping_genes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_of_int = ['SZC','BPD']\n",
    "overlapping_genes, gene_list = find_overlaps(all_genes_binary, dis_of_int)\n",
    "#overlapping_snps = find_overlaps(all_snps_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7984f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_snps = pd.DataFrame(index=all_snps_binary.columns, columns=all_snps_binary.columns, dtype=int)\n",
    "\n",
    "#Iterate through all pairs of disorders and count genes shared\n",
    "for disorder1 in all_snps_binary.columns:\n",
    "    for disorder2 in all_snps_binary.columns:\n",
    "        count=sum(all_snps_binary[disorder1] & all_snps_binary[disorder2])\n",
    "        shared_snps.at[disorder1,disorder2] = count\n",
    "\n",
    "#Add total number of genes in each disorder on the diagonal\n",
    "for disorder in all_snps_binary.columns:\n",
    "    total_count = all_snps_binary[disorder].sum()\n",
    "    shared_snps.at[disorder, disorder] = total_count\n",
    "\n",
    "#get lower triangular matrix including the diagonal\n",
    "#shared_lower = pd.DataFrame(np.tril(shared_genes), index=genes_binary.columns, columns=genes_binary.columns)\n",
    "disorders_snps = shared_snps.columns.tolist()\n",
    "disorder_matrix_snps = shared_snps.to_numpy()\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(shared_snps), k=1).astype(bool)\n",
    "\n",
    "# Set the values in the upper triangular part to NaN\n",
    "shared_snps[mask] = np.nan\n",
    "\n",
    "# Specify the size of the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Plot the heatmap\n",
    "with sns.axes_style('white'):\n",
    "    sns.heatmap(shared_snps, annot=True, fmt='.0f', cmap=ListedColormap(['white']), cbar=False)\n",
    "    plt.title('Shared SNPs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e09602",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_genes = pd.DataFrame(index=all_genes_binary.columns, columns=all_genes_binary.columns, dtype=int)\n",
    "\n",
    "#Iterate through all pairs of disorders and count genes shared\n",
    "for disorder1 in all_genes_binary.columns:\n",
    "    for disorder2 in all_genes_binary.columns:\n",
    "        count=sum(all_genes_binary[disorder1] & all_genes_binary[disorder2])\n",
    "        shared_genes.at[disorder1,disorder2] = count\n",
    "\n",
    "#Add total number of genes in each disorder on the diagonal\n",
    "for disorder in all_genes_binary.columns:\n",
    "    total_count = all_genes_binary[disorder].sum()\n",
    "    shared_genes.at[disorder, disorder] = total_count\n",
    "\n",
    "#get lower triangular matrix including the diagonal\n",
    "#shared_lower = pd.DataFrame(np.tril(shared_genes), index=genes_binary.columns, columns=genes_binary.columns)\n",
    "disorders = shared_genes.columns.tolist()\n",
    "disorder_matrix = shared_genes.to_numpy()\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(shared_genes), k=1).astype(bool)\n",
    "\n",
    "# Set the values in the upper triangular part to NaN\n",
    "shared_genes[mask] = np.nan\n",
    "\n",
    "# Specify the size of the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Plot the heatmap\n",
    "with sns.axes_style('white'):\n",
    "    sns.heatmap(shared_genes, annot=True, fmt='.0f', cmap=ListedColormap(['white']), cbar=False)\n",
    "    plt.title('Shared genes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2679d1088ddb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T10:15:43.383622800Z",
     "start_time": "2024-01-19T10:15:43.304537800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def hypergeometric_prob(matrix, disorder_list, M):\n",
    "\n",
    "    matrix_shape= matrix.shape\n",
    "    prob_matrix = np.zeros(matrix_shape)\n",
    "\n",
    "    for i in range(1, matrix_shape[0]):\n",
    "        for j in range(i):\n",
    "            x =matrix[i,j]\n",
    "            n = matrix[j,j]\n",
    "            N = matrix[i, i]\n",
    "            #print(M,n,x)\n",
    "            \n",
    "            prob = hypergeom.sf(x-1, M, n, N)\n",
    "            \n",
    "                \n",
    "            prob_matrix[i,j] = prob\n",
    "\n",
    "    return pd.DataFrame(prob_matrix, columns=disorder_list, index=disorder_list)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec09a70c5001ab1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_genes_10K=hypergeometric_prob(disorder_matrix, disorders, 10000)\n",
    "    \n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(prob_genes_10K, dtype=bool))\n",
    "\n",
    "# Set the upper triangular part to NaN to exclude it from the plot\n",
    "prob_genes_10K = prob_genes_10K.mask(mask)\n",
    "\n",
    "#Apply log transformation\n",
    "prob_genes_10K_log = np.log10(prob_genes_10K+1e-100)\n",
    "\n",
    "#reverse colormap\n",
    "cmap = 'Blues'\n",
    "cmap_reversed = cmap + '_r'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "plt.title('M = 10000 with log transformation')\n",
    "sns.heatmap(prob_genes_10K_log, annot=True,fmt='.2f',cmap=cmap_reversed, cbar=True)\n",
    "\n",
    "prob_genes_10Kfull_matrix = np.tril(prob_genes_10K) + np.tril(prob_genes_10K, -1).T\n",
    "\n",
    "prob_genes_10Kfull_df = pd.DataFrame(prob_genes_10Kfull_matrix, index=disorders, columns=disorders)\n",
    "prob_genes_10Kfull_df = prob_genes_10Kfull_df.fillna(1e-100)\n",
    "prob_genes_10Kfull_df_log = np.log10(prob_genes_10Kfull_df + 1e-100)\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.clustermap(prob_genes_10Kfull_df_log,cmap=cmap_reversed)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c413240",
   "metadata": {},
   "outputs": [],
   "source": [
    "finngen = pd.read_csv('FinnGen/FinnGen_table_all_diseases.csv', sep=';', index_col=0)\n",
    "disorder_list = finngen.index.values.tolist()\n",
    "fin_matrix = finngen.to_numpy()\n",
    "full_finngen_matrix2 = np.tril(finngen) + np.tril(finngen, -1).T\n",
    "finngen2 = pd.DataFrame(full_finngen_matrix2, index=disorder_list, columns=disorder_list)\n",
    "\n",
    "# Create a mask for the diagonal\n",
    "diagonal_mask = np.eye(len(finngen2), dtype=bool)\n",
    "mask = np.triu(np.ones_like(finngen2, dtype=bool), k=1)\n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "with sns.axes_style('white'):\n",
    "    sns.heatmap(finngen2,cmap=ListedColormap(['white']), annot=True, fmt='.0f', mask=mask, cbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "finngen_p = hypergeometric_prob(fin_matrix,disorder_list, 500000)\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(finngen_p, dtype=bool))\n",
    "\n",
    "# Set the upper triangular part to NaN to exclude it from the plot\n",
    "finngen_p = finngen_p.mask(mask)\n",
    "\n",
    "#Apply log transformation\n",
    "finngen_log = np.log10(finngen_p+1e-300)\n",
    "\n",
    "#reverse colormap\n",
    "cmap = 'Blues'\n",
    "cmap_reversed = cmap + '_r'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,20))\n",
    "plt.title('FinnGen with log transformation')\n",
    "sns.heatmap(finngen_log, annot=True,fmt='.2f',cmap=cmap_reversed, cbar=True)\n",
    "\n",
    "full_finngen_matrix = np.tril(finngen_p) + np.tril(finngen_p, -1).T\n",
    "full_finngen_df = pd.DataFrame(full_finngen_matrix, index=disorder_list, columns=disorder_list)\n",
    "full_finngen_df = full_finngen_df.fillna(1e-300)\n",
    "full_finngen_log = np.log10(full_finngen_df+1e-300)\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.clustermap(full_finngen_log,cmap=cmap_reversed)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.clustermap(full_finngen_log,cmap=cmap_reversed, method='ward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ea116",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.clustermap(full_finngen_log,cmap=cmap_reversed, method='single')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.clustermap(full_finngen_log,cmap=cmap_reversed, method='complete')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fc946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7070a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psych_overlap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
