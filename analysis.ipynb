{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T10:24:11.110625200Z",
     "start_time": "2024-01-18T10:24:11.053049800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from random import seed\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import hypergeom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all SNP files from FUMA analysis\n",
    "\n",
    "# Directory path\n",
    "directory_path = 'FUMA_dowloads_all_tissue/SNPs'\n",
    "\n",
    "snp_df_list = []\n",
    "disorder_names = []\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):  # Process only .txt files\n",
    "        # Extract disorder name from the filename\n",
    "        disorder_name = filename.split('_')[1].split('.')[0]\n",
    "        disorder_names.append(disorder_name)\n",
    "\n",
    "        # Read the file as a DataFrame\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "        # Choose columns of interest\n",
    "        df['disorder'] = disorder_name\n",
    "        df = df[['uniqID','rsID','gwasP','disorder']]\n",
    "        df = df.dropna()\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        # Append the DataFrame to the list\n",
    "        snp_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35effd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all eQTL files from FUMA analysis\n",
    "\n",
    "# Directory path\n",
    "directory_path = 'FUMA_dowloads_all_tissue/eQTL'\n",
    "\n",
    "\n",
    "gene_df_list = []\n",
    "disorder_names = []\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):  # Process only .txt files\n",
    "        # Extract disorder name from the filename\n",
    "        disorder_name = filename.split('_')[1].split('.')[0]\n",
    "        disorder_names.append(disorder_name)\n",
    "\n",
    "        # Read the file as a DataFrame\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "        # Choose columns of interest\n",
    "        df['disorder'] = disorder_name\n",
    "        df = df[['uniqID','symbol','tissue','disorder']]\n",
    "        df = df.dropna()\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        # Append the DataFrame to the list\n",
    "        gene_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" # Split data into psychiatric and other\n",
    "valid_strings = ['ADHD','ANOREXIA','ANXIETY','ASD','AUD','BPD','CUD','HOARDING','MDD','OCD','PTSD','SZC','TOURETTES']\n",
    "\n",
    "psych_snp_dfs = []\n",
    "other_snp_dfs = []\n",
    "psych_genes_dfs = []\n",
    "other_genes_dfs = []\n",
    "\n",
    "for df in snp_df_list:\n",
    "    # Check if any valid string is present in the 'disorder' column\n",
    "    if any(df['disorder'].str.contains(valid_string).any() for valid_string in valid_strings):\n",
    "        # If at least one valid string is present, append the dataframe to psych_snps_dfs\n",
    "        psych_snp_dfs.append(df)\n",
    "    else:\n",
    "        # If no valid string is present, append the dataframe to other_snp_dfs\n",
    "        other_snp_dfs.append(df)\n",
    "\n",
    "\n",
    "for df in gene_df_list:\n",
    "    # Check if any valid string is present in the 'disorder' column\n",
    "    if any(df['disorder'].str.contains(valid_string).any() for valid_string in valid_strings):\n",
    "        # If at least one valid string is present, append the dataframe to psych_genes_dfs\n",
    "        psych_genes_dfs.append(df)\n",
    "    else:\n",
    "        # If no valid string is present, append the dataframe to other_genes_dfs\n",
    "        other_genes_dfs.append(df) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # extract all genes from each disorder and save to file\n",
    "output_folder = 'genes_to_EnrichR'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each dataframe\n",
    "for df in gene_df_list:\n",
    "    # Extract disorder name\n",
    "    disorder_name = df['disorder'].iloc[0] \n",
    "    \n",
    "    # Extract unique symbols and save to txt file\n",
    "    unique_symbols = df['symbol'].drop_duplicates().tolist()\n",
    "    output_file = os.path.join(output_folder, f\"{disorder_name}.txt\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for symbol in unique_symbols:\n",
    "            f.write(f\"{symbol}\\n\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d313ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_snps = pd.concat(snp_df_list)\n",
    "snpID = concat_snps[['uniqID','rsID']]\n",
    "concat_genes = pd.concat(gene_df_list)\n",
    "merged_df = pd.merge(concat_genes,snpID,on=['uniqID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265efdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_matrix(df_list, column1,column2):\n",
    "    concatenated= pd.concat(df_list)\n",
    "    df = concatenated[[column1, column2]]\n",
    "    \n",
    "    return df.pivot_table(index=column1, columns=column2, aggfunc=lambda x: 1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ee07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snps_binary = make_binary_matrix(snp_df_list, 'rsID', 'disorder')\n",
    "all_genes_binary = make_binary_matrix(gene_df_list,'symbol', 'disorder')\n",
    "\"\"\" psych_snps_binary = make_binary_matrix(psych_snp_dfs,'rsID', 'disorder')\n",
    "genes_psych_binary = make_binary_matrix(psych_genes_dfs,'symbol', 'disorder') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_snps_binary.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_genes_binary.sum(axis=0))\n",
    "#all_genes_binary.to_csv('all_genes_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_combos(binary_df):\n",
    "# Set a seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_iterations = 10\n",
    "\n",
    "    # Get all possible combinations of disorders\n",
    "    all_combinations = []\n",
    "    for r in range(2,6):\n",
    "        all_combinations.extend(list(combinations(binary_df.columns, r)))\n",
    "\n",
    "    # Create an empty DataFrame with rows as each combination and columns for storing counts in each iteration\n",
    "    counts_df = pd.DataFrame(index=all_combinations, columns=range(1,num_iterations+1))\n",
    "\n",
    "    # Perform the iterations\n",
    "    for i in range(1,num_iterations+1):\n",
    "        # Permute the columns independently\n",
    "        permuted_df = binary_df.apply(np.random.permutation, axis=0)\n",
    "\n",
    "        iteration_counts = []\n",
    "\n",
    "        # Count occurrences for each combination in this iteration\n",
    "        for combo in all_combinations:\n",
    "            # Check if all disorders in the combination are present in each row\n",
    "            count = (permuted_df[list(combo)] == 1).all(axis=1).sum()\n",
    "            iteration_counts.append(count)\n",
    "\n",
    "        # Store the counts for this iteration in the dataFrame\n",
    "        counts_df[i] = iteration_counts\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143852d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_combos_real_data(binary_df):\n",
    "#Count all occurrences for each combination and store in a new dataframe\n",
    "\n",
    "    # Get all possible combinations of disorders \n",
    "    all_combinations = []\n",
    "    for r in range(2,6):\n",
    "        all_combinations.extend(list(combinations(binary_df.columns, r)))\n",
    "        \n",
    "    #Create empty dataframe to store the count\n",
    "    count_df = pd.DataFrame(index=all_combinations, columns=['Count'])\n",
    "\n",
    "    iteration_counts = []\n",
    "\n",
    "    # Count occurrences for each combination in this iteration \n",
    "    for combo in all_combinations:\n",
    "        # Check if all disorders in the combination are present in each row\n",
    "        count = (binary_df[list(combo)] == 1).all(axis=1).sum()\n",
    "        iteration_counts.append(count)\n",
    "\n",
    "    # Store the counts for this iteration in the counts_df DataFrame\n",
    "    count_df['Count'] = iteration_counts\n",
    "    \n",
    "    return count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#psych_snps_randomized = count_combos(psych_snps_binary)\n",
    "all_snps_randomized = count_combos(all_snps_binary)\n",
    "#psych_genes_randomized = count_combos(genes_psych_binary)\n",
    "all_genes_randomized = count_combos(all_genes_binary)\n",
    "\n",
    "#psych_snps_combo_count = count_combos_real_data(psych_snps_binary)\n",
    "all_snps_combo_count = count_combos_real_data(all_snps_binary)\n",
    "#psych_genes_combo_count = count_combos_real_data(genes_psych_binary)\n",
    "all_genes_combo_count = count_combos_real_data(all_genes_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate z-scores and sort the result\n",
    "\n",
    "def calculate_z_score(df, df_rand, threshold, count):\n",
    "    np.random.seed(42)\n",
    "    #calculate mean and standard deviation\n",
    "    means = df_rand.mean(axis=1)\n",
    "    std = df_rand.std(axis=1)\n",
    "\n",
    "     # Add  new columns\n",
    "    \n",
    "    df_rand['mean'] = means\n",
    "    df_rand['std'] = std\n",
    "    df_rand['actual'] = df['Count']\n",
    "    \n",
    "    new_df = df_rand[['actual', 'mean', 'std']]\n",
    "    \n",
    "    #Make copies to avoid warnings\n",
    "    new_df_copy = new_df.copy()\n",
    "    \n",
    "    \n",
    "    # Calculate Z-scores \n",
    "    new_df_copy['z-score'] = (new_df_copy['actual'] - new_df_copy['mean']) / new_df_copy['std']\n",
    "    \n",
    "    \n",
    "    sorted_df = new_df_copy.sort_values(by='z-score', ascending=False)\n",
    "    \n",
    "    # Replace infinite values in the \"z-score\" column with NaN\n",
    "    sorted_df['z-score'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Drop rows with NaN values in the \"z-score\" column\n",
    "    sorted_df.dropna(subset=['z-score'], how='any', inplace=True)\n",
    "\n",
    "    return sorted_df[(sorted_df['z-score'] >= threshold) & (sorted_df['actual'] >= count)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e52b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_psych_snps2 = calculate_z_score(psych_snps_combo_count, psych_snps_randomized,2,5)\n",
    "z_all_snps2 = calculate_z_score(all_snps_combo_count, all_snps_randomized,2,5)\n",
    "#z_psych_genes2 = calculate_z_score(psych_genes_combo_count, psych_genes_randomized,2,5)\n",
    "z_all_genes2 = calculate_z_score(all_genes_combo_count, all_genes_randomized,2,5)\n",
    "\n",
    "#z_psych_snps3 = calculate_z_score(psych_snps_combo_count, psych_snps_randomized,3,5)\n",
    "z_all_snps3 = calculate_z_score(all_snps_combo_count, all_snps_randomized,3,5)\n",
    "#z_psych_genes3 = calculate_z_score(psych_genes_combo_count, psych_genes_randomized,3,5)\n",
    "z_all_genes3 = calculate_z_score(all_genes_combo_count, all_genes_randomized,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all_genes3.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97730",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {'No. of combinations with z-value >= 2':[ len(z_all_snps2),len(z_all_genes2)],'No. of combinations with z-value >= 3':[len(z_all_snps3),len(z_all_genes3)]}\n",
    "z_df = pd.DataFrame(data=z, index=[ 'SNPs (all)', 'genes (all)'])\n",
    "z_df.index.name='Combinations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 500 SNPs ranked by significance\n",
    "top_snp_list = []\n",
    "for df in snp_df_list:\n",
    "    sorted = df.sort_values(by=['gwasP'])\n",
    "    top_snps = sorted.iloc[:500]\n",
    "    top_snps.reset_index(drop=True,inplace=True)\n",
    "    top_snp_list.append(top_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23871cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  randomly select a given number of SNPs\n",
    "np.random.seed(42)\n",
    "all_linkage = []\n",
    "\n",
    "# Perform hierarchical clustering 10 times and store the linkage matrices\n",
    "for _ in range(1):\n",
    "    sampled_dfs = []\n",
    "    for df in top_snp_list:\n",
    "        sampled = df.sample(3, axis=0)\n",
    "        sampled.reset_index(inplace=True, drop=True)\n",
    "        sampled_dfs.append(sampled)\n",
    "\n",
    "    sampled_binary = make_binary_matrix(sampled_dfs, 'rsID', 'disorder')\n",
    "    print('The number of SNPs shared between at least 2 disorders:', (sampled_binary.sum(axis=1) >= 2).sum())\n",
    "\n",
    "    # Hierarchical clustering\n",
    "    linkage_matrix = hierarchy.linkage(sampled_binary.T, method='average')\n",
    "    all_linkage.append(linkage_matrix)\n",
    "\n",
    "# Plot the dendrogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    dendrogram = hierarchy.dendrogram(linkage_matrix, labels=sampled_binary.columns)\n",
    "    plt.xlabel('Disorders')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title('Hierarchical Clustering Dendrogram sampled from top 500 SNPs')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()  \n",
    "\n",
    "\"\"\" # Compute the mean linkage matrix\n",
    "mean_linkage = np.mean(all_linkage, axis=0)\n",
    "print(mean_linkage)\n",
    "# Plot the dendrogram for the mean linkage matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram = hierarchy.dendrogram(mean_linkage)\n",
    "plt.xlabel('Disorders')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Consensus Hierarchical Clustering Dendrogram')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c330e40c7802c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T12:56:19.970956Z",
     "start_time": "2024-01-17T12:56:19.923473300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to find the overlaps in SNPs and genes\n",
    "\n",
    "def find_overlaps(binary_matrix, disorders_of_interest):\n",
    "    overlaps = []\n",
    "    overlapping_genes = set()\n",
    "\n",
    "    for index, row in binary_matrix.iterrows():\n",
    "        ones = {col for col, val in row.items() if val == 1 and col in disorders_of_interest}\n",
    "\n",
    "        if ones and ones == set(disorders_of_interest):\n",
    "            overlaps.append((index, ones))\n",
    "            overlapping_genes.add(index)\n",
    "\n",
    "    # Write overlapping genes to a file\n",
    "    with open('genes_to_enrichR.txt', 'w') as file:\n",
    "        for gene in overlapping_genes:\n",
    "            file.write(gene + '\\n')\n",
    "\n",
    "    return overlaps, list(overlapping_genes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_of_int = ['SZC','BPD']\n",
    "overlapping_genes, gene_list = find_overlaps(all_genes_binary, dis_of_int)\n",
    "#overlapping_snps = find_overlaps(all_snps_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7984f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_snps = pd.DataFrame(index=all_snps_binary.columns, columns=all_snps_binary.columns, dtype=int)\n",
    "\n",
    "#Iterate through all pairs of disorders and count genes shared\n",
    "for disorder1 in all_snps_binary.columns:\n",
    "    for disorder2 in all_snps_binary.columns:\n",
    "        count=sum(all_snps_binary[disorder1] & all_snps_binary[disorder2])\n",
    "        shared_snps.at[disorder1,disorder2] = count\n",
    "\n",
    "#Add total number of genes in each disorder on the diagonal\n",
    "for disorder in all_snps_binary.columns:\n",
    "    total_count = all_snps_binary[disorder].sum()\n",
    "    shared_snps.at[disorder, disorder] = total_count\n",
    "\n",
    "#get lower triangular matrix including the diagonal\n",
    "#shared_lower = pd.DataFrame(np.tril(shared_genes), index=genes_binary.columns, columns=genes_binary.columns)\n",
    "disorders_snps = shared_snps.columns.tolist()\n",
    "disorder_matrix_snps = shared_snps.to_numpy()\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(shared_snps), k=1).astype(bool)\n",
    "\n",
    "# Set the values in the upper triangular part to NaN\n",
    "shared_snps[mask] = np.nan\n",
    "\n",
    "# Specify the size of the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(shared_snps, annot=True, fmt='.0f', cmap='Greys', cbar=False)\n",
    "plt.title('Shared SNPs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e09602",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_genes = pd.DataFrame(index=all_genes_binary.columns, columns=all_genes_binary.columns, dtype=int)\n",
    "\n",
    "#Iterate through all pairs of disorders and count genes shared\n",
    "for disorder1 in all_genes_binary.columns:\n",
    "    for disorder2 in all_genes_binary.columns:\n",
    "        count=sum(all_genes_binary[disorder1] & all_genes_binary[disorder2])\n",
    "        shared_genes.at[disorder1,disorder2] = count\n",
    "\n",
    "#Add total number of genes in each disorder on the diagonal\n",
    "for disorder in all_genes_binary.columns:\n",
    "    total_count = all_genes_binary[disorder].sum()\n",
    "    shared_genes.at[disorder, disorder] = total_count\n",
    "\n",
    "#get lower triangular matrix including the diagonal\n",
    "#shared_lower = pd.DataFrame(np.tril(shared_genes), index=genes_binary.columns, columns=genes_binary.columns)\n",
    "disorders = shared_genes.columns.tolist()\n",
    "disorder_matrix = shared_genes.to_numpy()\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(shared_genes), k=1).astype(bool)\n",
    "\n",
    "# Set the values in the upper triangular part to NaN\n",
    "shared_genes[mask] = np.nan\n",
    "\n",
    "# Specify the size of the heatmap\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(shared_genes, annot=True, fmt='.0f', cmap='Greys', cbar=False)\n",
    "plt.title('Shared genes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c212c44c14e8605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T12:57:07.895543Z",
     "start_time": "2024-01-17T12:57:07.863440300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" #function to make binary matrix with randobly selected snps\n",
    "def make_random_binary_matrix(number_i, list_of_snps, number_of_snps):\n",
    "    random_binary_list = []\n",
    "    for i in range(number_i):\n",
    "        random = select_snps_randomly(list_of_snps, number_of_snps)\n",
    "        concatenated_random = pd.concat(random)\n",
    "    \n",
    "        binary = concatenated_random.pivot_table(index='rsID', columns='disorder', aggfunc=lambda x: 1, fill_value=0)\n",
    "        random_binary_list.append(binary)\n",
    "    return random_binary_list \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2679d1088ddb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T10:15:43.383622800Z",
     "start_time": "2024-01-19T10:15:43.304537800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def hypergeometric_prob(matrix, disorder_list, M):\n",
    "\n",
    "    matrix_shape= matrix.shape\n",
    "    prob_matrix = np.zeros(matrix_shape)\n",
    "\n",
    "    for i in range(1, matrix_shape[0]):\n",
    "        for j in range(i):\n",
    "            x =matrix[i,j]\n",
    "            n = matrix[j,j]\n",
    "            N = matrix[i, i]\n",
    "            #print(M,n,x)\n",
    "            \n",
    "            prob = hypergeom.sf(x-1, M, n, N)\n",
    "            \n",
    "                \n",
    "            prob_matrix[i,j] = prob\n",
    "\n",
    "    return pd.DataFrame(prob_matrix, columns=disorder_list, index=disorder_list)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec09a70c5001ab1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_genes_10K=hypergeometric_prob(disorder_matrix, disorders, 10000)\n",
    "    \n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(prob_genes_10K, dtype=bool))\n",
    "\n",
    "# Set the upper triangular part to NaN to exclude it from the plot\n",
    "prob_genes_10K = prob_genes_10K.mask(mask)\n",
    "\n",
    "#Apply log transformation\n",
    "prob_genes_10K_log = np.log10(prob_genes_10K+1e-100)\n",
    "\n",
    "#reverse colormap\n",
    "cmap = 'Blues'\n",
    "cmap_reversed = cmap + '_r'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "plt.title('M = 10000 with log transformation')\n",
    "sns.heatmap(prob_genes_10K_log, annot=True,fmt='.2f',cmap=cmap_reversed, cbar=True)\n",
    "\n",
    "prob_genes_10Kfull_matrix = np.tril(prob_genes_10K) + np.tril(prob_genes_10K, -1).T\n",
    "\n",
    "prob_genes_10Kfull_df = pd.DataFrame(prob_genes_10Kfull_matrix, index=disorders, columns=disorders)\n",
    "prob_genes_10Kfull_df = prob_genes_10Kfull_df.fillna(1e-100)\n",
    "prob_genes_10Kfull_df_log = np.log10(prob_genes_10Kfull_df + 1e-100)\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.clustermap(prob_genes_10Kfull_df_log,cmap=cmap_reversed)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c413240",
   "metadata": {},
   "outputs": [],
   "source": [
    "finngen = pd.read_csv('FinnGen/FinnGen_table_all_diseases.csv', sep=';', index_col=0)\n",
    "disorder_list = finngen.index.values.tolist()\n",
    "fin_matrix = finngen.to_numpy()\n",
    "full_finngen_matrix2 = np.tril(finngen) + np.tril(finngen, -1).T\n",
    "finngen2 = pd.DataFrame(full_finngen_matrix2, index=disorder_list, columns=disorder_list)\n",
    "\n",
    "# Create a mask for the diagonal\n",
    "diagonal_mask = np.eye(len(finngen2), dtype=bool)\n",
    "mask = np.triu(np.ones_like(finngen2, dtype=bool), k=1)\n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "sns.heatmap(finngen2,cmap='Greys', annot=True, fmt='.0f', mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "finngen_p = hypergeometric_prob(fin_matrix,disorder_list, 500000)\n",
    "\n",
    "# Create a mask for the upper triangular part\n",
    "mask = np.triu(np.ones_like(finngen_p, dtype=bool))\n",
    "\n",
    "# Set the upper triangular part to NaN to exclude it from the plot\n",
    "finngen_p = finngen_p.mask(mask)\n",
    "\n",
    "#Apply log transformation\n",
    "finngen_log = np.log10(finngen_p+1e-100)\n",
    "\n",
    "#reverse colormap\n",
    "cmap = 'Blues'\n",
    "cmap_reversed = cmap + '_r'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,20))\n",
    "plt.title('FinnGen with log transformation')\n",
    "sns.heatmap(finngen_log, annot=True,fmt='.2f',cmap=cmap_reversed, cbar=True)\n",
    "\n",
    "full_finngen_matrix = np.tril(finngen_p) + np.tril(finngen_p, -1).T\n",
    "full_finngen_df = pd.DataFrame(full_finngen_matrix, index=disorder_list, columns=disorder_list)\n",
    "full_finngen_df = full_finngen_df.fillna(1e-100)\n",
    "full_finngen_log = np.log10(full_finngen_df+1e-100)\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.clustermap(full_finngen_log,cmap=cmap_reversed)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psych_overlap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
